# Summary and implications

Accurate representation of clouds in large-scale (global) climate models is of critical importance, but has remained elusive for model developers. An important test of the fidelity of models is the comparison of simulated climate against available observations of the physical climate. For cloud properties, this often means comparison with satellite-retrievals, but these types of comparisons have traditionally been challenging due to fundamental limitations in both the satellite retrieval process and in the model formulation of clouds. An increasingly common approach to dealing with these limitations is to use the simulator framework, whereby pseudo-retrievals are simulated from model cloud fields to account for some of the known features and limitations of specific satellite retrievals. While this approach has enabled more consistent comparisons between modeled and observed cloud properties, it is demonstrated here that limitations in both the retrievals and in the models themselves remain unaccounted for.

The simulation of satellite-retrieved cloud properties from the description of clouds provided by a large-scale model is a multi-step process, involving 1) downscaling model gridbox-mean quantities to scales approximating satellite pixels, 2) simulating the individual satellite retrievals, and 3) aggregating the pixel-scale pseudo-retrievals into statistical summary products analogous to those produced for the individual satellite instruments. In general there can be uncertainties associated with each of these steps, and the primary goal of this study has been to quantify (and reduce) uncertainties and biases related to both steps 1) and 2).

The performance of the MISR simulator is evaluated here by comparing pseudo-retrievals simulated from CloudSat and CALIPSO data with retrievals from MISR. The MISR simulator is able to correct for many of the features of the MISR retrieval and, in general, cloud top heights retrieved from CloudSat and CALIPSO are in much better agreement with MISR after using the MISR-simulator to account for the features of the MISR retrieval. Mid and high-topped clouds are in particularly good agreement between MISR and CloudSat/CALIPSO retrievals when using the MISR simulator. Large differences remain in total and low-topped clouds, however, due to ambiguities in retrieving small (sub-pixel) scale clouds. The differences highlighted here between MISR and CloudSat/CALPISO cloud area are discouraging because they represent a fundamental uncertainty in the quantification of low-topped and total cloud area, making robust comparisons of modeled cloud area with these satellite retrievals difficult. More importantly, these differences point to the fragility of cloud area as a measure of cloudiness. This has motivated the use of joint histograms of cloud top height and optical depth for model evaluation because comparisons can be limited to categories for which uncertainties are expected to be lower. For example, @pincus_et_al_2012 suggest limiting comparisons of cloud area to only those pixels and gridboxes with cloud optical depth $\tau > 1.3$ in order to limit the uncertainties that arise due to sampling broken cloud scenes. While this does improve agreement among the different satellite retrievals of cloud area from MISR, ISCCP, and MODIS, errors arising in the *simulated* satellite retrievals due to homogenizing cloud condensate are shown here to affect not only total cloud area but also optically thick ($\tau > 23$) cloud area. Thus, additional care must be taken to account for these inherent errors and uncertainties.

Because current global climate models do not explicitly resolve clouds at the scales at which satellite retrievals are performed, the additional step of downscaling cloud properties to pixel scales is needed before simulating the satellite retrievals. This process depends on additional assumptions about the unresolved cloud properties. In particular, cloud (and precipitation) condensate is nearly always assumed to be horizontally homogeneous on the scale of model gridboxes, and clouds are assumed to follow a simple "maximum-random" overlap. MISR-simulated cloud area is sensitive to both of these assumptions, while simulated CloudSat radar reflectivity is sensitive primarily to the treatment of precipitation and to the subgrid-scale variability in condensate. These errors can be quite large regionally, and have significant consequences for the suitability of these simulators for model evaluation. The errors in CloudSat-simulated radar reflectivity that arise due to these assumptions are particularly large and, until these errors are corrected for, CloudSat radar reflectivity is probably not a suitable quantity for model evaluation.

The errors in simulated pseudo-retrievals that arise due to the generation of subcolumns from model gridbox-mean quantities can be significantly reduced with an improved subcolumn treatment that accounts for both horizontal variability in condensate amount and more realistic overlap of clouds and precipitation. The subcolumn scheme described by [@raisanen_et_al_2004] is implemented here for use in COSP and the new scheme results in a significant reduction in errors due to generating subcolumns from gridbox means. The performance of this improved subcolumn generator depends, however, on the specification of cloud and precipitation overlap and rank correlation statistics, as well as on the subgrid-scale variance in condensate. These are all quantities which will need to be parameterized in order to use this improved subcolumn generator with traditional large-scale global models. Using overlap statistics and variance calculated directly from the high-resolution baseline simulation used in the sensitivity tests here results in a significant reduction in errors, but more modest results are obtained using a simple parameterization of these quantities. Nonetheless, the improvements demonstrated using the calculated quantities shows that this framework can significantly improve comparisons between models and satellite retrievals and that further work to better parameterize these quantities will be worthwhile.

It is important to note that the errors identified here are intrinsic to the model evaluation process itself and not directly connected to inherent errors in the formulation of a particular model. In other words, these errors arise on the *diagnostic* side, not on the model side. This is significant, because it means that if we fail to account for these errors we may draw incorrect conclusions about the models we evaluate. In particular, it is important that the assumptions used in generating these diagnostics are consistent with assumptions used elsewhere in the model in order to draw conclusions about models consistent with their internal formulation.

The importance of overlap and condensate heterogeneity extend beyond just the simulation of pseudo-satellite retrievals. In particular, both of these characteristics of clouds are important in simulating radiative fluxes and in predicting microphysical process rates. This makes future work to improve the characterization of these quantities even more important. With the growing interest in statistical or PDF-based cloud schemes in large-scale models, it might ultimately make sense for subgrid-scale variance (and, perhaps, condensate probability distributions) to be specified by these schemes within the model, rather than by some external parameterization of the variance with an assumed distribution. Certainly, if such an assumption is made within the model, it makes sense for the same assumptions to be used on the diagnostic end. Regardless, it is clear that the representation (or implicit assumption) of cloud properties at scales below those resolved by global climate models is in dire need of improvement.

While the primary goal of this work has been to evaluate and reduce the errors in satellite diagnostics that arise due to unresolved cloud properties, this work also presents a step forward in the understanding and quantification of these unresolved cloud and precipitation properties. Traditionally, analysis of small-scale cloud statistics has been limited to direct in-situ observations of cloud properties using aircraft observations or tethered balloons, retrievals using a few select ground-based sites, retrievals using satellite observations, or limited area CRM or LES studies. Each of these sources of information carries with them specific strengths and limitations. The use of model output from the Multi-scale Modeling Framework presented here demonstrates a potentially new avenue for exploring the small (subgrid-scale) properties of cloud and precipitation condensate distributions. Using such model output for the study of cloud and precipitation condensate distributions has the advantage of providing resolved information about small-scale cloud and precipitation systems with global coverage, spanning a full range of atmospheric conditions and cloud regimes. This comprehensive spatial coverage is not possible using in-situ observations or ground-based retrievals and satellite-based retrievals of cloud properties are notoriously difficult to interpret and fraught with uncertainties and limitations. Of course, this approach is limited by the fidelity of the model itself, and the fact that simulated cloud systems may not be consistent with clouds in the physical atmosphere. However, as global-scale high-resolution modeling frameworks like the MMF become more sophisticated and simulations improve (or as computational resources grow to accommodate true global cloud resolving models), the prospect of using such global simulations for the purpose of informing parameterizations for use in large-scale models becomes more reasonable.

